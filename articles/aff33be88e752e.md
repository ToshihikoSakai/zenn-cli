---
title: "OpenCALM-7BをM2 Macで動かす"
emoji: "💬"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: [python, AI, LLM]
published: true
---


# はじめに
この記事では、CyberAgent社が公開したLLMであるOpenCALM-7BのモデルをM2 Macのローカル環境で実行したTipsを記載します。

# OpenCALMとは

OpenCALMはCyberAgent社が開発したデコーダ型の事前学習済みモデルです。
商用利用可能なライセンスとなっており、このモデルをベースにチューニングを行うことが可能です。

https://www.cyberagent.co.jp/news/detail/id=28817

OpenCALM-7BモデルはHuggingFaceで公開されています。

https://huggingface.co/cyberagent/open-calm-7b

# PCスペック
実行したPCのスペックは以下のとおりです。

```
メモリ：64GB
チップ：Apple M2 Max
OS：Ventura 13.4.1 
```


# 実行手順

ローカルに`.ipynb`ファイルを作成しました。（仮想環境は`Python 3.9.6`です）

## ライブラリインストール

以下のライブラリをインストールします。

```python
!pip install transformers accelerate
```

## モデルとトークナイザーのダウンロード

次に、モデルとトークナイザーをダウンロードします。
自身の環境だと約55分程度かかりました。

```python
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

model = AutoModelForCausalLM.from_pretrained(
    "cyberagent/open-calm-7b", 
    device_map="auto", 
    torch_dtype=torch.float16
)
tokenizer = AutoTokenizer.from_pretrained("cyberagent/open-calm-7b")

```

ダウンロードしたモデルは`~/.cache/huggingface/hub/models--cyberagent--open-calm-7b`配下に保存されます。
次回以降はこのキャッシュから読み込むことができます。

## プロンプトの準備と推論の実行

```python

prompt = "Q:日本の首都はどこですか？ A.「"

inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
with torch.no_grad():
    tokens = model.generate(
        **inputs,
        max_new_tokens=64,
        do_sample=True,
        temperature=0.1,
        pad_token_id=tokenizer.pad_token_id,
    )
    
output = tokenizer.decode(tokens[0], skip_special_tokens=True)
print(output)

```

実行後、以下エラーが発生しました。

```bash
RuntimeError: MPS does not support cumsum op with int64 input.
```

以下コメントを参考にpytorchをnightlyバージョンにすると上記エラーは解消しました。
https://github.com/pytorch/pytorch/issues/96610#issuecomment-1593230620

```
!pip install --upgrade --no-deps --force-reinstall --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu
```

エラー解消後の実行結果。質問と答えが繰り返し出力される。
```
Q:日本の首都はどこですか？ A.「東京都」です。Q:日本の首都を教えてください。A:東京都です。....
```

# 参考

https://note.com/npaka/n/n2185b422a2f2